#+TITLE: Indoor Localization
#+DATE: Time-stamp: <2017-08-17 21:21:45 Kyeong Soo (Joseph) Kim>
#+OPTIONS: toc:t

This is a repository for research on indoor localization based on wireless
fingerprinting techniques. For more details, please visit [[http://kyeongsoo.github.io/research/projects/indoor_localization/index.html][XJTLU SURF project
home page]].

* 2017-08-17
- Implement [[./python/bf_classification.py][a new program]], which calculates accuracies separately for building
  and floor classification, to investigate the hierarchical nature of the
  classification problem at hand; the deep-learning-based place recognition
  system described in [[https://arxiv.org/abs/1611.02049v2][the key paper]] does not take into account this and carries
  out classification based on flattened labels (i.e., (building, floor) ->
  'building-floor'). We are now considering two options to guarantee 100%
  accuracy for the building classification:
  + Hierarchical classifier with a tree structure and multiple classifiers and
    data sets, which is a conventional approach and a reference for this
    investigation;
  + One classifier with a weighted loss function (e.g., [[https://www.jstage.jst.go.jp/article/imt/10/3/10_488/_pdf][this]]).

* 2017-08-15
- Today, we further simplified the building/floor classification system by
  removing a hidden layer from the classifier (therefore no dropout), resulting
  in the configuration of '520-64-4-13' (including input and output layers) with
  loss=7.050603e-01 and accuracy=9.234923e-01 ([[./results/indoor_localization_deep_learning_out_20170815-203448.org][results]]). This might mean that
  the 4-dimensional data from the SAE encoder (64-4) can be linearly
  separable. Due to training of SAE encoder weights for the combined system,
  however, it needs further investigation.

* 2017-08-14
- We investigated whether a couple of strong RSSs in a fingerprint dominate the
  classification performance in building/floor classification. After many trials
  with different configurations, we could obtain more than 90% accuracies with
  the stacked-autoencoder (SAE) having 64-4-64 hidden layers (i.e., just 4
  dimension) and the classifier having just one 128-node hidden layer (the
  results are [[./results/indoor_localization_deep_learning_out_20170814-184009.org][here]]). This implies that a small number of RSSs from access points
  (APs) deployed in a building/floor can give enough information for the
  building/floor classification; the localization on the same floor, by the way,
  would be quite different, where RSSs from possibly many APs have a significant
  impact on the localization performance.

* 2017-08-13
- We finally obtained [[./results/indoor_localization_deep_learning.org][more than 90% accuracies]] from [[./python/indoor_localization_deep_learning.py][this version]], which are
  comparable to the results of [[https://arxiv.org/abs/1611.02049v2][the key paper]]; refer to the [[https://keras.io/getting-started/sequential-model-guide/#compilation][multi-class
  clarification example]] for classifier parameter settings.
- We [[./python/indoor_localization-2.ipynb][replace the activation functions of the hidden-layer from 'tanh' to 'relu']]
  per the second answer to [[https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer][this question]]. The results are [[./results/indoor_localization-2_20170813.csv][here]]. Compared to the
  case with 'tanh', however, the results seem to not improve (a bit in line with
  the gut-feeling suggestions from [[https://datascience.stackexchange.com/questions/10048/what-is-the-best-keras-model-for-multi-class-classification][this]]).

* 2017-08-12
- We first tried [[./python/indoor_localization-1.ipynb][a feed-forward classifier with just one hidden layer]] per the
  comments from [[https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw][this]]. The results are [[./results/indoor_localization-1_20170812.csv][here]] (* /nh/: number of hidden layer
  nodes, /dr/: [[https://en.wikipedia.org/wiki/Dropout_(neural_networks)][dropout]] rate, /loss/: [[http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#theano.tensor.nnet.nnet.categorical_crossentropy][categorical cross-entropy]], /acc/: accuracy
  *).
