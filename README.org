#+TITLE: Indoor Localization
#+DATE: Time-stamp: <2017-08-14 18:52:28 Kyeong Soo (Joseph) Kim>
#+OPTIONS: toc:t

This is a repository for research on indoor localization based on wireless
fingerprinting techniques. For more details, please visit [[http://kyeongsoo.github.io/research/projects/indoor_localization/index.html][XJTLU SURF project home page]].

* 2017-08-14
- We investigated whether a couple of strong RSSs in a fingerprint dominate the
  classification performance in buildig/floor classification. After many trials
  with different configurations, we could obtain more than 90% accuracies with
  the stacked-autoencoder (SAE) having 64-4-64 hidden layers (i.e., just 4
  dimension) and the classifier having just one 128-node hidden layer (the
  results are [[./results/indoor_localization_deep_learning_out_20170814-184009.org][here]]). This implies that just a small number of RSSs from access
  points (APs) deployed in a building/floor can give enough information for the
  building/floor classification, which would be quite different from the
  localization on the same floor where there are RSSs from possibly many APs.

* 2017-08-13
- We finally obtained [[./results/indoor_localization_deep_learning.org][more than 90% accuracies]] from [[./python/indoor_localization_deep_learning.py][this version]], which are
  comparable to the results of [[https://arxiv.org/abs/1611.02049v2][the key paper]]; refer to the [[https://keras.io/getting-started/sequential-model-guide/#compilation][multi-class
  clarification example]] for classifier parameter settings.
- We [[./python/indoor_localization-2.ipynb][replace the activation functions of the hidden-layer from 'tanh' to 'relu']]
  per the second answer to [[https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer][this qustion]]. The results are [[./results/indoor_localization-2_20170813.csv][here]]. Compared to the
  case with 'tanh', however, the results seem to not improve (a bit inline with
  the gut-feeling suggestions from [[https://datascience.stackexchange.com/questions/10048/what-is-the-best-keras-model-for-multi-class-classification][this]]).

* 2017-08-12
- We first tried [[./python/indoor_localization-1.ipynb][a feed-forward classifier with just one hidden layer]] per the
  comments from [[https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw][this]]. The results are [[./results/indoor_localization-1_20170812.csv][here]] (* /nh/: number of hidden layer
  nodes, /dr/: [[https://en.wikipedia.org/wiki/Dropout_(neural_networks)][dropout]] rate, /loss/: [[http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#theano.tensor.nnet.nnet.categorical_crossentropy][categorical cross-entropy]], /acc/: accuracy
  *).
